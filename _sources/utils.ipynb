{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils \n",
    "This page shows the inside of the utils.py script, which allows for common functions to be easily used across different notebooks in the book without redefining them each time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import notebook dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import xarray as xr\n",
    "from glob import glob\n",
    "import sys\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.ma as ma\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import pyproj\n",
    "from datetime import date\n",
    "from matplotlib.axes import Axes\n",
    "from cartopy.mpl.geoaxes import GeoAxes\n",
    "GeoAxes._pcolormesh_patched = Axes.pcolormesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getWinterDateRange\n",
    "Gets date range for winter season/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWinterDateRange(start_year, end_year): \n",
    "    \"\"\" Gets date range for winter season/s\n",
    "    Args: \n",
    "        start_year (int): start year \n",
    "        end_year (int): end year \n",
    "        \n",
    "    Returns: \n",
    "        winters (list): list of dates for all winter seasons in the input range (i.e: ['1980-11','1980-12','1981-01',\n",
    "         '1981-02','1981-03','1981-04')\n",
    "    \"\"\"\n",
    "    winters = []\n",
    "    for year in range(start_year, end_year, 1):\n",
    "        winters += pd.date_range(start = str(year) + '-11', end = str(year + 1) + '-04', freq = 'MS')\n",
    "    return winters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getIS2Data\n",
    "Gets ICESat-2 data for provided date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIS2Data(dataPath, dates): \n",
    "    \"\"\"Gets ICESat-2 data for provided date range\n",
    "    \n",
    "    Args: \n",
    "        dataPath (str): path to local directory of ICESat-2 data \n",
    "        dates (list): pandas Timestamp objects generated by getWinterDateRange\n",
    "        \n",
    "    Returns: \n",
    "        is2 (xarray dataset): ICESat-2 data or NONE if file does not exist for inputted date range\n",
    "    \"\"\"\n",
    "    is2List = [] #empty list for compiling xarray DataArray objects\n",
    "    for date in dates: \n",
    "        try:\n",
    "            filename = glob(dataPath+ 'IS2*' + date.strftime('%y') + date.strftime('%m') + '*.nc')[0]\n",
    "        except: \n",
    "            print('Cannot find files; check date range or filepath')\n",
    "            return None\n",
    "        is2 = xr.open_dataset(filename)\n",
    "        is2 = is2.assign_coords({'time': date})\n",
    "        is2List.append(is2)\n",
    "    is2Data = xr.concat(is2List, dim = 'time') #concatenate all DataArray objects into a single DataArray\n",
    "    return is2Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getSICData\n",
    "Gets sea ice concentration data for provided date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSICData(dataPath, dates): \n",
    "    \"\"\"Gets sea ice concentration data for provided date range\n",
    "    \n",
    "    Args: \n",
    "        dataPath (str): path to local directory of sea ice concentration data \n",
    "        dates (list): pandas Timestamp objects generated by getWinterDateRange\n",
    "        \n",
    "    Returns: \n",
    "        sicData (xarray dataset): sea ice concentration data or NONE if file does not exist for inputted date range\n",
    "    \"\"\"\n",
    "    sicList = [] #empty list for compiling xarray DataArray objects\n",
    "    for date in dates: \n",
    "        try:\n",
    "            filename = glob(dataPath+ 'seaice_conc_monthly*' + date.strftime('%Y') + date.strftime('%m') + '*.nc')[0]\n",
    "        except: \n",
    "            print('Cannot find files; check date range, filepath or if glob is imported')\n",
    "            return None\n",
    "        dropVariables = ['goddard_merged_seaice_conc_monthly','goddard_bt_seaice_conc_monthly', 'goddard_nt_seaice_conc_monthly']\n",
    "        sicList.append(xr.open_dataset(filename, drop_variables = dropVariables))\n",
    "    sicData = xr.concat(sicList , dim = 'time', combine_attrs = 'override', data_vars = 'minimal') #concatenate all DataArray objects into a single DataArray\n",
    "    return sicData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getRegionMask\n",
    "Gets NSIDC region mask for map projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRegionMask(dataPath): \n",
    "    \"\"\"Gets NSIDC region mask for map projection\n",
    "    \n",
    "     Args:\n",
    "         dataPath (str): path to NSIDC region mask\n",
    "         \n",
    "     Returns: \n",
    "         shapedMask (numpy array): NSIDC arctic region mask gridded to shape [448, 304]\n",
    "         shapedLons (numpy array): longitudes gridded to shape [448, 304]\n",
    "         shapedLats (numpy array): latitudes gridded to shape [448, 304] \n",
    "    \"\"\" \n",
    "    gridShape = [448, 304] #shape of grid to reshape data to \n",
    "    \n",
    "    regionMask = open(dataPath + '/sect_fixed_n.msk', 'rb') #open region mask \n",
    "    shapedMask = np.reshape(np.fromfile(file = regionMask, dtype='uint8'), gridShape) #reshape mask to grid shape\n",
    "    \n",
    "    maskLons = open(dataPath + '/psn25lons_v3.dat', 'rb') #open region mask longitudes\n",
    "    maskLats = open(dataPath + '/psn25lats_v3.dat', 'rb') #open region mask latitudes\n",
    "    shapedLons = np.reshape(np.fromfile(file = maskLons, dtype='<i4')/100000., gridShape) #reshape longitudes to grid shape\n",
    "    shapedLats = np.reshape(np.fromfile(file = maskLats, dtype='<i4')/100000., gridShape) #reshape latitudes to grid shape\n",
    "\n",
    "    return shapedMask, shapedLons, shapedLats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getPIOMASData\n",
    "Gets PIOMAS mean monthly sea ice thickness data for an input time range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPIOMASData(dataPath, startYear = 1978, endYear = 2020): \n",
    "    \"\"\"Gets PIOMAS mean monthly sea ice thickness data for an input time range. \n",
    "    \n",
    "    Args: \n",
    "        dataPath (str): path to local directory of PIOMAS data \n",
    "        startYear (int): year to start loading data from (defaul to 1978)\n",
    "        endYear (int): year to stop loading data from (default to 2020)\n",
    "    \n",
    "    Returns: \n",
    "        PIOMAS_data (xarray DataArray): PIOMAS data with descriptive coordinates and attributes\n",
    "        \n",
    "    Note: last available PIOMAS data was from July 2020 at the time of creation of this function\n",
    "    \"\"\"\n",
    "    dataList = [] #empty list for compiling data\n",
    "\n",
    "    for year in range(startYear, endYear + 1, 1):     \n",
    "        data = open(dataPath + '/heff.H' + str(year), 'rb') \n",
    "        if year == 2020: #need special reshaping for 2020 because we dont have a full year of data\n",
    "            period = 7\n",
    "        else:\n",
    "            period = 12\n",
    "        dataList += list(np.fromfile(file = data, dtype='f').reshape([period, 120, 360]))\n",
    "    \n",
    "    #add latitude and longitude \n",
    "    gridP = np.loadtxt(dataPath + 'grid.dat.txt')\n",
    "    lonsP = gridP[0:4320, :].flatten()\n",
    "    lonsP = np.reshape(lonsP, [120,360])\n",
    "    latsP = gridP[4320:, :].flatten()\n",
    "    latsP = np.reshape(latsP, [120,360])\n",
    "    \n",
    "    #load dataList as an xarray DataArray with descriptive attributes and coordinates\n",
    "    time = pd.date_range(start = str(startYear), end = str(endYear) + '-07', freq = 'MS')\n",
    "    PIOMAS_attrs = {'units': 'meters', 'long_name': 'PIOMAS sea ice thickness', 'data description': 'PIOMAS monthly mean sea ice thickness', 'citation': 'Zhang, J.L. and D.A. Rothrock, “Modeling global sea ice with a thickness and enthalpy distribution model in generalized curvilinear coordinates“, Mon. Weather Rev., 131, 845-861, 2003'}\n",
    "    PIOMAS_data = xr.DataArray(dataList, dims = ['time','x','y'], coords = {'time': time, 'longitude': (('x','y'), lonsP), 'latitude': (('x','y'), latsP)}, attrs = PIOMAS_attrs)\n",
    "    \n",
    "    return PIOMAS_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getDriftData\n",
    "Gets weekly NSIDC sea ice drift data for the Arctic, resamples monthly, and returns a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDriftData(dataPath):\n",
    "    \"\"\"Gets weekly NSIDC sea ice drift data for the Arctic, resamples monthly, and returns a dataset\n",
    "    \n",
    "    Args: \n",
    "        dataPath (str): path to local directory of weekly drift data \n",
    "\n",
    "    Returns: \n",
    "        monthlyDrifts (xarray DataArray): sea ice drift data, resampled to monthly means, with descriptive coordinates and attributes\n",
    "        \n",
    "    Note: This function uses two different datasets from the NSIDC for drift in order to get the most recent data. Drift dataset from 1978-2018 was combined with quicklook drift dataset from 2019-present, maintaining attitributes of the 1978-2018 dataset\n",
    "    \"\"\"\n",
    "    def get_uv_from_xy(xdrift, ydrift, lon):\n",
    "        \"\"\"convert the drift vectors to zonal/meridional\n",
    "        \"\"\"\n",
    "        alpha = lon*np.pi/180. #convert longitudes to radians \n",
    "        uvelT = ydrift*np.sin(alpha) + xdrift*np.cos(alpha)\n",
    "        vvelT = ydrift*np.cos(alpha) - xdrift*np.sin(alpha) \n",
    "        return uvelT, vvelT\n",
    "    \n",
    "    #combine nc weekly files into a single xarray dataset\n",
    "    files = [xr.open_dataset(dataPath + f) for f in os.listdir(dataPath) if os.path.isfile(dataPath + f) and f.endswith('.nc')]\n",
    "    weeklyDrifts = xr.concat(files, dim = 'time')\n",
    "\n",
    "    #get transformed u,v variables and add to dataset\n",
    "    uvelT, vvelT = get_uv_from_xy(weeklyDrifts.u, weeklyDrifts.v, weeklyDrifts.longitude)\n",
    "    weeklyDrifts = weeklyDrifts.assign(drifts_uT = uvelT, drifts_vT = vvelT)\n",
    "    weeklyDrifts.drifts_uT.attrs = {'description':'along-x component of the ice motion (u variable) converted to zonal/meridional'}\n",
    "    weeklyDrifts.drifts_vT.attrs = {'description':'along-y component of the ice motion (v variable) converted to zonal/meridional'}\n",
    "\n",
    "    #resample to get monthly data \n",
    "    monthlyDrifts = weeklyDrifts.resample(time='MS', keep_attrs = True).mean()\n",
    "\n",
    "    #convert to same time format as ICESat-2 \n",
    "    monthlyDrifts = monthlyDrifts.assign_coords(time = [pd.to_datetime(date.strftime('%m-%d-%Y')) for date in monthlyDrifts.time.values])\n",
    "    \n",
    "    #add attributes \n",
    "    for var in monthlyDrifts.data_vars: \n",
    "        monthlyDrifts[var].attrs = weeklyDrifts[var].attrs\n",
    "        if var == 'drifts_uT' or var == 'drifts_vT': \n",
    "            monthlyDrifts[var].attrs['long_name'] = 'NSIDC sea ice motion vectors'\n",
    "            monthlyDrifts[var].attrs['units'] = 'cm/s'\n",
    "    monthlyDrifts.attrs['njkeeney comment'] = 'drift dataset from 1978-2018 was combined with quicklook drift dataset from 2019-present, maintaining attitributes of the 1978-2018 dataset'\n",
    "    monthlyDrifts.attrs['citation'] = 'Tschudi, M., W. N. Meier, J. S. Stewart, C. Fowler, and J. Maslanik. 2019. Polar Pathfinder Daily 25 km EASE-Grid Sea Ice Motion Vectors, Version 4. Weekly sea ice motion. Boulder, Colorado USA. NASA National Snow and Ice Data Center Distributed Active Archive Center. doi: https://doi.org/10.5067/INAWUWO7QH7B. July 2020.'\n",
    "    \n",
    "    return monthlyDrifts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotOneMonth\n",
    "Plots map of the arctic on North Pole Stereo projection with one month of data overlayed, along with the sea ice edge for each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotOneMonth(dataset, dataVar, month, minval, maxval, cbarTicks = None, cmap = 'viridis'): \n",
    "    \"\"\"Plots map of the arctic on North Pole Stereo projection with one month of data overlayed, along with the sea ice edge for each month.\n",
    "   \n",
    "    Args:\n",
    "        dataset (xr Dataset): dataset from google bucket\n",
    "        dataVar (str): variable of interest\n",
    "        month (str): month and year of interest, i.e. 'Dec 2019' (does not need to be in any particular format)\n",
    "        minval, maxval (int): minimum and maximum values for the data variable \n",
    "        cbarTicks (list or np array of length 2): ticks to use on colorbar (default to [minval + 1, maxval +1])\n",
    "        cmap (str, optional): color map (default to viridis)\n",
    "        \n",
    "    Returns:\n",
    "        Figure displayed in notebook \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #define projection and transform\n",
    "    proj = ccrs.NorthPolarStereo(central_longitude = -45)\n",
    "    transform = ccrs.PlateCarree()\n",
    "    \n",
    "    #initialize the figure and axes \n",
    "    plt.figure(figsize=(6, 6))\n",
    "    ax = plt.axes(projection = proj)\n",
    "    \n",
    "    #define arguments if not inputted \n",
    "    cbarTicks = np.arange(minval, maxval + 1, 1) if cbarTicks is None else cbarTicks\n",
    "    \n",
    "    #plot sea ice concentraion \n",
    "    SICarray = dataset['seaice_conc_monthly_cdr'].sel(time = month).where(dataset['region_mask']!=21) #dont plot contour along coastlines\n",
    "    \n",
    "    #stackexchange workaround for plotting on a rotated grid\n",
    "    lonGreater = ma.masked_greater(SICarray.longitude.values, -0.01)\n",
    "    lonLesser = ma.masked_less(SICarray.longitude.values, 0)\n",
    "    latGreater = ma.MaskedArray(SICarray.latitude.values, mask = lonGreater.mask)\n",
    "    latLesser = ma.MaskedArray(SICarray.latitude.values, mask = lonLesser.mask)\n",
    "    dataGreater = ma.MaskedArray(SICarray.values[0], mask = lonGreater.mask)\n",
    "    dataLesser = ma.MaskedArray(SICarray.values[0], mask = lonLesser.mask)\n",
    "    \n",
    "    #plot contour using each part of the 2 masked data sets\n",
    "    im2a = ax.contour(lonGreater, latGreater, dataGreater, levels = [0.5], transform = transform, colors = 'magenta', linewidths = 0.9, zorder=5, alpha=1)\n",
    "    im2b = ax.contour(lonLesser, latLesser, dataLesser, levels = [0.5], transform = transform, colors = 'magenta', linewidths = 0.9, zorder=5, alpha=1)\n",
    "    #im = ax.contour(SICarray.longitude.values, SICarray.latitude.values, SICarray.values[0], levels = [0.15], transform = transform, colors = 'magenta', linewidths = 0.8, zorder=15, alpha=1)\n",
    "    \n",
    "    #plot the data\n",
    "    dataset[dataVar].where(dataset['seaice_conc_monthly_cdr'] > 0.5).sel(time = month).plot(x = 'longitude', y = 'latitude', vmin = minval, vmax = maxval, extend = 'both', \n",
    "                    ax = ax, add_colorbar = True, transform = transform, zorder = 2, cmap = cmap, \n",
    "                    cbar_kwargs = {'label': dataset[dataVar].attrs['long_name'] + ' (' + dataset[dataVar].attrs['units'] + ')', 'orientation': 'horizontal', 'shrink': 0.75, 'pad': 0.025})\n",
    "    \n",
    "    #add features to the map\n",
    "    ax.coastlines(linewidth=0.15, color = 'black', zorder = 10) #add coastlines \n",
    "    ax.add_feature(cfeature.LAND, color ='0.95', zorder = 5) #add land \n",
    "    ax.add_feature(cfeature.LAKES, color = 'grey', zorder = 5) #add lakes \n",
    "    ax.gridlines(draw_labels = False, linewidth = 0.25, color = 'gray', alpha = 0.7, linestyle = '--', zorder = 6) #add gridlines\n",
    "    ax.set_extent([-179, 179, 55, 90], crs = transform) #zoom in so map only displays the Arctic\n",
    "    ax.set_title(month + \": \" + dataset[dataVar].attrs['long_name'], fontweight = 'medium')\n",
    "    \n",
    "    #display figure in notebook \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotWinterMaps\n",
    "Plot maps of the arctic on North Pole Stereo projection with several months of data overlayed, along with the sea ice edge for each month. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotWinterMaps(dataset, dataVar, winter, minval, maxval, cbarTicks = None, title = \"\", cmap = 'viridis'):\n",
    "    \"\"\"Plot maps of the arctic on North Pole Stereo projection with several months of data overlayed, along with the sea ice edge for each month. \n",
    "   \n",
    "    Args:\n",
    "        dataset (xr Dataset): dataset from google bucket \n",
    "        dataVar (str): variable of interest\n",
    "        winter (list): list of pandas Timestamp objects generated by getWinterDateRange(startYear, endYear)\n",
    "        minval, maxval (int): minimum and maximum values for the data variable \n",
    "        cbarTicks (list or np array of length 2): ticks to use on colorbar (default to [minval + 1, maxval +1])\n",
    "        title (str, optional): title of subplots (default to empty string)\n",
    "        cmap (str, optional): color map (default to viridis)\n",
    "\n",
    "    Returns:\n",
    "        Figure displayed in notebook \n",
    "\n",
    "    \"\"\"\n",
    "    #format time for plotting \n",
    "    timeFormatted = list(pd.to_datetime(winter).strftime('%B %Y'))\n",
    "    \n",
    "    #define projection and transform\n",
    "    proj = ccrs.NorthPolarStereo(central_longitude = -45)\n",
    "    transform = ccrs.PlateCarree()\n",
    "    \n",
    "    #define arguments if not inputted \n",
    "    cbarTicks = np.arange(minval, maxval + 1, 1) if cbarTicks is None else cbarTicks\n",
    "    \n",
    "    #plot the data\n",
    "    im = dataset[dataVar].where(dataset['seaice_conc_monthly_cdr'] > 0.5).sel(time = winter).plot.pcolormesh(x = 'longitude', y = 'latitude', vmin = minval, vmax = maxval, cmap = cmap,\n",
    "        extend='both', levels=20, transform = transform, col='time', add_colorbar = True, zorder = 2, figsize = (8,8), col_wrap = 3,\n",
    "        cbar_kwargs = {'ticks': cbarTicks, 'label': dataset[dataVar].attrs['long_name'] + ' (' + dataset[dataVar].attrs['units'] + ')', 'orientation': 'horizontal', 'shrink': 0.4, 'pad': 0.03},\n",
    "        subplot_kws = {'projection': proj})\n",
    "    \n",
    "    #add a title\n",
    "    plt.suptitle(title + ': ' + dataset[dataVar].attrs['long_name'], fontsize = 20, y = 0.99, fontweight = 'medium')\n",
    "\n",
    "    i = 0 #indexer to go through timeFormatted and winter arrays and assign the correct data to each month\n",
    "    for ax in im.axes.flat:\n",
    "        ax.coastlines(linewidth=0.25, color = 'black', zorder = 10) #add coastlines \n",
    "        ax.add_feature(cfeature.LAND, color ='0.95', zorder = 5) #add land \n",
    "        ax.add_feature(cfeature.LAKES, color = 'grey', zorder = 5) #add lakes \n",
    "        ax.gridlines(draw_labels = False, linewidth = 0.25, color = 'gray', alpha = 0.75, linestyle='--', zorder = 6) #add gridlines\n",
    "        ax.set_extent([-179, 179, 50, 90], crs = transform) #zoom in so map only displays the Arctic\n",
    "\n",
    "        #plot sea ice concentration \n",
    "        SICarray = dataset['seaice_conc_monthly_cdr'].sel(time = winter[i]).where(dataset['region_mask']!=21) #dont plot contour along coastlines\n",
    "        lonGreater = ma.masked_greater(SICarray.longitude.values, -0.01)\n",
    "        lonLesser = ma.masked_less(SICarray.longitude.values, 0)\n",
    "        latGreater = ma.MaskedArray(SICarray.latitude.values, mask = lonGreater.mask)\n",
    "        latLesser = ma.MaskedArray(SICarray.latitude.values, mask = lonLesser.mask)\n",
    "        dataGreater = ma.MaskedArray(SICarray.values, mask = lonGreater.mask)\n",
    "        dataLesser = ma.MaskedArray(SICarray.values, mask = lonLesser.mask)\n",
    "        im2a = ax.contour(lonGreater, latGreater, dataGreater, levels = [0.5], transform = transform, colors = 'magenta', linewidths = 0.8, zorder=5, alpha=1)\n",
    "        im2b = ax.contour(lonLesser, latLesser, dataLesser, levels = [0.5], transform = transform, colors = 'magenta', linewidths = 0.8, zorder=5, alpha=1)\n",
    "    \n",
    "        #set title of each plot to formatted date \n",
    "        ax.set_title(timeFormatted[i])\n",
    "        \n",
    "        #update indexer \n",
    "        i += 1\n",
    "    \n",
    "    #display figure in notebook \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### restrictRegionally\n",
    "Restrict dataset to input regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restrictRegionally(dataset, regionKeyList): \n",
    "    \"\"\"Restrict dataset to input regions.\n",
    "    \n",
    "    Args: \n",
    "        dataset (xr Dataset): dataset generated by Load_IS2 notebook\n",
    "        regionKeyList (list): list of region keys to restrict data to \n",
    "        \n",
    "    Returns: \n",
    "        regionalDataset (xr Dataset): dataset with restricted data to input regions\n",
    "    \"\"\"\n",
    "    \n",
    "    def checkKeys(regionKeyList, regionTbl): \n",
    "        \"\"\"Check that regionKeyList was defined correctly\n",
    "\n",
    "        Raises: \n",
    "            ValueError if regionKeyList was not defined correctly \n",
    "            warning if all data was removed from the dataset\n",
    "        \"\"\"\n",
    "        if type(regionKeyList) != list: #raise a ValueError if regionKeyList is not a list \n",
    "            raise ValueError('regionKeyList needs to be a list. \\nFor example, if you want to restrict data to the Beaufort Sea, define regionKeyList = [13]')\n",
    "\n",
    "        for key in regionKeyList: \n",
    "            if key not in list(regionTbl['key']): \n",
    "                raise ValueError('Region key ' + str(key) + ' does not exist in region mask. \\n Redefine regionKeyList with key numbers from table')\n",
    "\n",
    "        if len(regionKeyList) == 0: \n",
    "            warnings.warn('You removed all the data from the dataset. Are you sure you wanted to do this? \\n If not, make sure the list regionKeyList is not empty and try again. \\n If you intended to keep data from all regions, set regionKeyList = list(tbl[\\\"key\\\"])')\n",
    " \n",
    "    #create a table of keys and labels\n",
    "    regionMask = dataset.region_mask.attrs\n",
    "    regionTbl = pd.DataFrame({'key': regionMask['keys'], 'label': regionMask['labels']})\n",
    "    \n",
    "    #call function to check if regionKeyList was defined correctly\n",
    "    checkKeys(regionKeyList, regionTbl)\n",
    "    \n",
    "    #keys to remove (all keys that are note listed in regionKeyList)\n",
    "    keysToRemove = [key for key in list(regionTbl['key']) if key not in regionKeyList]\n",
    "    \n",
    "    #filter elements from the ice thickness DataArray where the region is the desired region\n",
    "    regionalDataset = dataset.copy()\n",
    "    for var in dataset.data_vars: \n",
    "        if var != 'seaice_conc_monthly_cdr':\n",
    "            regionalVar = regionalDataset[var]\n",
    "            for key in keysToRemove: \n",
    "                regionalVar = regionalVar.where(regionalVar['region_mask'] != key)\n",
    "            regionalDataset[var] = regionalVar\n",
    "    \n",
    "    #find name of labels \n",
    "    labels = [regionTbl[regionTbl['key'] == key]['label'].item() for key in regionKeyList]\n",
    "    \n",
    "    #add new attributes describing changes made to the dataset\n",
    "    if len(labels) < len(regionTbl['key']): \n",
    "        if set(regionKeyList) == set([10,11,12,13,15]): #convert to sets so unordered lists are compared\n",
    "            regionalDataset.attrs['regions with data'] = 'Inner Arctic'\n",
    "        else:    \n",
    "            regionalDataset.attrs['regions with data'] = ('%s' % ', '.join(map(str, labels)))\n",
    "        print('Regions selected: ' + regionalDataset.attrs['regions with data'])\n",
    "    else: \n",
    "        regionalDataset.attrs['regions with data'] = 'All'\n",
    "        print('Regions selected: All \\nNo regions will be removed')\n",
    "    \n",
    "    return regionalDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### progressBar\n",
    "Display a progress bar inside a for loop. Used in code development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progressBar(i, tot): \n",
    "    \"\"\"\n",
    "    Function: display a progress bar inside a for loop \n",
    "    Input: \n",
    "        -i: iteration number (integer value)\n",
    "        -tot: total number of iterations (integer value)\n",
    "    \"\"\"\n",
    "    j = (i + 1) / tot\n",
    "    sys.stdout.write('\\r [%-20s] %d%% complete' % ('='*int(20*j), 100*j))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "is2intenv",
   "language": "python",
   "name": "is2intenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
